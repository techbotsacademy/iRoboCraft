<!DOCTYPE html>
<html>
<head>
  <title>Mouth Open Close Detection</title>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

  <style>
    body {
      text-align: center;
      background: #111;
      color: white;
      font-family: Arial;
    }
    video {
      border: 2px solid cyan;
      border-radius: 10px;
    }
  </style>
</head>

<body>

  <h1 id="status">Loading...</h1>
  <video id="video" width="640" height="480" autoplay></video>

  <script>
    const video = document.getElementById("video");
    const statusText = document.getElementById("status");

const faceMesh = new FaceMesh({
  locateFile: (file) =>
    `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
});

    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults(results => {
      if (!results.multiFaceLandmarks) return;

      const landmarks = results.multiFaceLandmarks[0];

      // Upper lip & lower lip points
      const upperLip = landmarks[13];
      const lowerLip = landmarks[14];

      const lipDistance = Math.abs(upperLip.y - lowerLip.y);

      if (lipDistance > 0.015) {
        statusText.innerText = "MOUTH OPEN ðŸ˜®";
      } else {
        statusText.innerText = "MOUTH CLOSED ðŸ™‚";
      }
    });

    const camera = new Camera(video, {
      onFrame: async () => {
        await faceMesh.send({ image: video });
      },
      width: 640,
      height: 480
    });

    camera.start();
  </script>

</body>
</html>